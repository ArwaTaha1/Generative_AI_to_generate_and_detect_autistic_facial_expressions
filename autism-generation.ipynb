{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1024609,"sourceType":"datasetVersion","datasetId":564001},{"sourceId":3301539,"sourceType":"datasetVersion","datasetId":1997065},{"sourceId":11313720,"sourceType":"datasetVersion","datasetId":7068644},{"sourceId":11409832,"sourceType":"datasetVersion","datasetId":7146871},{"sourceId":11426369,"sourceType":"datasetVersion","datasetId":6808767},{"sourceId":11430126,"sourceType":"datasetVersion","datasetId":7109748}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Initialization and StyleGAN2 importing","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport warnings\nimport torch\nimport json","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n !git clone https://github.com/ArwaTaha1/stylegan2-ada-pytorch.git\n#!pip install ninja","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -y peft\n!pip install torch==1.11.0 torchvision==0.12.0\n\n# !pip install numpy scipy scikit-image pillow tqdm tensorboard matplotlib\n# !pip install pyspng\n# !pip install click","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reformat all images to jpeg and RGB and resize to 512x512","metadata":{}},{"cell_type":"code","source":"\ndef clean_dataset(input_folder, output_folder, target_size=(512, 512)):\n    os.makedirs(output_folder, exist_ok=True)\n    \n    for filename in tqdm(os.listdir(input_folder)):\n        input_path = os.path.join(input_folder, filename)\n        name, _ = os.path.splitext(filename)\n        output_path = os.path.join(output_folder, f\"{name}.jpg\")  # Save as JPG\n        \n        try:\n            img = Image.open(input_path)\n            img = img.convert(\"RGB\")  # Ensure RGB mode\n            img = img.resize(target_size, Image.LANCZOS)\n            img.save(output_path, format=\"JPEG\", quality=95)\n        except Exception as e:\n            print(f\"Failed to process {input_path}: {e}\")\n\nclean_dataset(\"/kaggle/input/autism/autism/train/autistic\", \"/kaggle/working/data/gan/images/autistic\")\nclean_dataset(\"/kaggle/input/autism/autism/train/non_autistic\", \"/kaggle/working/data/gan/images/non_autistic\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Check if all images are up to standard","metadata":{}},{"cell_type":"code","source":"IMAGE_PATH = '/kaggle/working/data/gan/images/autistic'\nIMAGE_PATH1 = '/kaggle/working/data/gan/images/non_autistic'\nfiles = [f for f in listdir(IMAGE_PATH) if isfile(join(IMAGE_PATH, f))]\nfiles1 = [f for f in listdir(IMAGE_PATH1) if isfile(join(IMAGE_PATH1, f))]\n\nbase_size = None\nfor file in tqdm(files):\n  file2 = os.path.join(IMAGE_PATH,file)\n  img = Image.open(file2)\n  sz = img.size\n  if base_size and sz!=base_size:\n    print(f\"Inconsistant size: {file2}\")\n  elif img.mode!='RGB':\n    print(f\"Inconsistant color format: {file2}\")\n  else:\n    base_size = sz\n      \nbase_size = None      \nfor file in tqdm(files1):\n  file2 = os.path.join(IMAGE_PATH,file)\n  img = Image.open(file2)\n  sz = img.size\n  if base_size and sz!=base_size:\n    print(f\"Inconsistant size: {file2}\")\n  elif img.mode!='RGB':\n    print(f\"Inconsistant color format: {file2}\")\n  else:\n    base_size = sz","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !rm -R /kaggle/working/kaggle","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate dataset.json manually","metadata":{}},{"cell_type":"code","source":"dataset_root = \"/kaggle/working/data/gan/images\"\nlabel_map = {\"autistic\": 0, \"non_autistic\": 1}\nlabels = []\n\nfor class_name, label in label_map.items():\n    class_dir = os.path.join(dataset_root, class_name)\n    for fname in os.listdir(class_dir):\n        if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n            rel_path = f\"{class_name}/{fname}\"\n            labels.append([rel_path, label])\n\n\nwith open(os.path.join(dataset_root, \"dataset.json\"), \"w\") as f:\n    json.dump({\"labels\": labels}, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Convert the images","metadata":{}},{"cell_type":"code","source":"!python /kaggle/working/stylegan2-ada-pytorch/dataset_tool.py --source /kaggle/working/data/gan/images --dest /kaggle/working/data/gan/dataset.zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !rm -R /kaggle/working/data\n# !rm -R /kaggle/working/images_cleaned\n# !rm -R /kaggle/working/seed0100.png","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Initial Training","metadata":{}},{"cell_type":"code","source":"EXPERIMENTS = \"/kaggle/working/data/gan/experiments\"\nDATA = \"/kaggle/working/data/gan/dataset.zip\"\nSNAP = 10\n\ncmd = f\"/usr/bin/python3 /kaggle/working/stylegan2-ada-pytorch/train.py --snap {SNAP} --outdir {EXPERIMENTS} --data {DATA} --cond=1 --mirror=1\"\n!{cmd}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Resume Training","metadata":{}},{"cell_type":"code","source":"EXPERIMENTS = \"/kaggle/working/data/gan/experiments\"\nDATA = \"/kaggle/working/data/gan/dataset.zip\"\nSNAP = 10\nRESUME = '/kaggle/input/third-gan-run/data/gan/experiments/00000-dataset-cond-auto1-resumecustom/network-snapshot-000120.pkl'\ncmd = f\"/usr/bin/python3 /kaggle/working/stylegan2-ada-pytorch/train.py --snap {SNAP} --resume {RESUME} --outdir {EXPERIMENTS} --data {DATA} --cond=1 \"\n!{cmd}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate images","metadata":{}},{"cell_type":"code","source":"!python /kaggle/working/stylegan2-ada-pytorch/generate.py \\\n  --outdir /kaggle/working/ \\\n  --trunc=1 \\\n  --seeds=100 \\\n  --network=/kaggle/input/third-gan-run/data/gan/experiments/00000-dataset-cond-auto1-resumecustom/network-snapshot-000120.pkl \\\n  --class=0","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}